# ğŸ§  QA Sentinel â€“ Multi-Agent Test Case Generation System  
Google Ã— Kaggle â€” Agentic AI Intensive (Capstone Project)

QA Sentinel is a fully automated, production-style **multi-agent QA pipeline** powered by **Googleâ€™s Agent Development Kit (ADK)** and **Gemini models**.  

It converts a user story into a complete QA package:  
Features â†’ Scenarios â†’ Test Cases â†’ Edge Cases â†’ Bug Risks â†’ Validation.

---
## ğŸ“Œ Problem Statement

Manually generating QA assets is slow, inconsistent, and error-prone.  
QA teams must:
- Interpret vague user stories  
- Break them into features & scenarios  
- Ensure acceptance criteria coverage  
- Write structured Given/When/Then test cases  
- Perform quality checks across multiple outputs  

This process is repetitive and leads to:
- Coverage gaps  
- Inconsistent structure  
- Validation overhead  
- Slower QA cycles  

We needed a system that automates this entire workflow with consistency and quality.

---

## ğŸš€ Solution Overview

**QA Sentinel** automates end-to-end QA planning using a coordinated set of AI agents.

The system performs:

### âœ” Story Analysis & Decomposition  
Breaks user stories into features, scenarios, insights.

### âœ” Automated Test Case Generation  
Produces structured test cases with GWT steps, preconditions, and expected results.

### âœ” Edge Case & Bug Risk Discovery  
Expands test coverage intelligently.

### âœ” Multi-Agent Validation  
Ensures correctness of scenarios, structure, coverage, and alignment.

### âœ” Memory-Augmented Reasoning  
Uses FAISS vector memory to improve future outputs.

### âœ” Deterministic Evaluation  
Consistency scoring + A2A (Agent-to-Agent) meta-evaluation.

### âœ” MCP Output Tools  
Exports results as JSON/Markdown for real QA workflow usage.

This creates a **robust, repeatable, high-coverage QA generation pipeline**.

---

## ğŸ§© System Architecture

### High-Level System Architecture

```mermaid
    "Input"
        [User Story<br/>Title, Description, AC, QA Context]
    
    "Orchestrator Layer"
        [QASentinelOrchestrator<br/>Session Management & Coordination]
    
    "Agent Layer"
        [Story Planner Loop<br/>ADK v1 Loop]
        [Test Case Generator Loop<br/>ADK v1 Loop]
        [Global Validator Loop<br/>ADK v1 Loop]
    
    "Memory Layer"
        [QAStyleMemory<br/>FAISS Vector DB]
        [SessionStore<br/>In-Memory State]
    
    "Evaluation Layer"
        [ConsistencyEvaluator<br/>Rule-based]
        [A2AEvaluator<br/>Meta-evaluation]
    
    "Export Layer"
        [MCP Export Server<br/>Markdown & JSON]
    
    "Output"
        [Structured JSON<br/>Test Cases, Edge Cases,<br/>Bug Risks, Validation]

```

---

## ğŸ› ï¸ Agents Breakdown

### 1. Story Planner (LoopAgent)
Breaks the story into:
- Features (3â€“8 items)
- Structured scenarios (SC-1, SC-2â€¦)
- AC mapping
- Notes & insights

Validation ensures:
- Nonâ€‘empty features
- Every AC has â‰¥1 scenario
- Strict JSON formatting

---

### 2. Test Case Generator (LoopAgent)
Generates:
- 1â€“3 test cases per scenario  
- Preconditions  
- Gherkin Given/When/Then steps  
- Expected results  
- Edge cases  
- Bug risks  

Validation ensures:
- All scenarios referenced
- G/W/T structure exists
- Expected result exists

---

### 3. Global Validator Agent
Checks:
- Coverage completeness  
- Step quality  
- Logical flow  
- Missing scenarios/tests  
- JSON structure  

---

## ğŸ§  Memory Layer (FAISS)
Stores:
- Title  
- AC  
- Planner output  
- Test case output  

Used for:
- Similar test case pattern retrieval  
- Style consistency  

---

## ğŸ“ Evaluation Layer
### âœ” ConsistencyEvaluator
Rule-based scoring of:
- Scenario coverage  
- GWT structure  
- Scenario reference  
- Output structure  

### âœ” A2AEvaluator  
Simulates agent-to-agent evaluation:
- Component scores  
- Reasoning  
- Recommendations  
- Metrics  

---

## ğŸ§° Tools & Utilities

### MCP File Export Tool
- Saves JSON  
- Saves Markdown  

### Logging Layer
- Rotating logs  
- Structured timestamps  

### Tracing Module
- Tracks duration of each stage  

### SessionStore
- Tracks planner/testcase/validator outputs  

### JSON Extractor
- Robust ADK event parsing  

---

## ğŸ“‚ Project Structure

```
qa-sentinel/
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ story_planner_agent.py
â”‚   â”œâ”€â”€ testcase_generator_agent.py
â”‚   â”œâ”€â”€ global_validator_agent.py
â”‚   â”œâ”€â”€ orchestrator_agent.py
â”‚   â””â”€â”€ adk_v1_compat.py
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ qa_style_memory.py
â”‚   â””â”€â”€ session_store.py
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ consistency_evaluator.py
â”‚   â””â”€â”€ a2a_evaluator.py
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ file_export_mcp.py
â”‚
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ logging_config.py
â”‚   â””â”€â”€ tracing.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.py
â”‚   â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_input_story.md
â”‚   â””â”€â”€ sample_output_tests.md
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ cloudrun_deploy.md
â”‚   â””â”€â”€ agent_engine_setup.md
â”‚
â”œâ”€â”€ exports/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ§ª How to Run Locally

### 1. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Add Your Gemini API Key

Create `.env`:

```env
GOOGLE_API_KEY=your_key_here
```

### 4. Run Pipeline

```bash
python main_interactive.py
```

**What happens next:**
- `It will ask for User story title, Description, Acceptance Criteria and QA context.`
- `Then the pipeline will run and you will get the complete output.`

**Outputs will be saved in:**
- `exports/markdown/`
- `exports/json/`

---

## ğŸ” Example Output (Summary)

- **Planner generates**: SC-1 ... SC-n scenarios
- **Generator produces**: TC-1 ... TC-n test cases
- **Validator returns**: `{"valid": true, "errors": []}`
- **Evaluators produce**: Scores 0â€“100
- **Markdown files**: Saved automatically

### Sample Planner Output

```json
{
  "features": ["Profile Update - Name", "Profile Update - Email"],
  "scenarios": [
    {
      "scenario_id": "SC-1",
      "title": "Update Name Successfully",
      "acceptance_criteria": "User can update their name",
      "tags": ["positive", "name"]
    }
  ],
  "notes": ["Consider localization for name field"],
  "acceptance_criteria_input": ["User can update their name", ...]
}
```

### Sample Test Case Output

```json
{
  "test_cases": [
    {
      "id": "TC-1",
      "title": "Verify Successful Name Update - SC-1",
      "preconditions": ["User is logged in"],
      "steps": [
        "Given the user is on the profile page",
        "When the user updates their first name to 'John'",
        "Then the profile page should display 'John' as the updated name"
      ],
      "expected_result": "User's name is successfully updated and displayed."
    }
  ],
  "edge_cases": [{"id": "EC-1", "description": "Test with extremely long names"}],
  "bug_risks": [{"id": "BR-1", "description": "XSS vulnerability in name fields"}]
}
```

---

## â­ Why This Matters (Value Statement)

**QA Sentinel reduces:**
- â±ï¸ 6â€“10 hours of QA planning per sprint
- ğŸ”„ Manual duplication across acceptance criteria
- âŒ Gap-failures between scenarios & test cases

**And increases:**
- âœ… Consistency
- âœ… Coverage
- âœ… Edge-case discovery
- âœ… QA productivity

It represents the future of agentic QA automation.

---

## ğŸ”— Project Links

**GitHub Repo**: https://github.com/MhussainD4772/Capstone-Project-Agentic-AI-

---

## ğŸ“„ License

MIT License â€” see LICENSE file.

---

<div align="center">

**Built with Google ADK v1, Gemini 2.0 Flash, and Python**

â­ **Star this repo if you find it useful!** â­

</div>
